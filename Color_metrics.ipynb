{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "from scipy.optimize import curve_fit, root\n",
    "from sklearn.metrics import r2_score, auc\n",
    "from scipy import stats\n",
    "from scipy.signal import deconvolve\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Plotting and image libraries\n",
    "from matplotlib import pyplot as plt, style\n",
    "import matplotlib as mpl\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Other utilities\n",
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from tqdm import tqdm\n",
    "# import ruptures as rpt\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "# Jupyter notebook settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Style settings\n",
    "style.use('ggplot')  # or plt.style.use('ggplot')\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# Color choice\n",
    "color_choice = ['#F8DDA4', '#C8D5B9', '#68B0AB', '#4A7C59'][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_z_score(intensity):\n",
    "    median_int = np.median(intensity)\n",
    "    mad_int = np.median([np.abs(intensity -median_int)])\n",
    "    modified_z_scores = 0.6745 * (intensity- median_int) / mad_int\n",
    "    return modified_z_scores\n",
    "\n",
    "def fixer(y,m=3, th=7):\n",
    "    try:\n",
    "        th = 7 # binarization threshold. \n",
    "        spikes = abs(np.array(modified_z_score(np.diff(y)))) > th\n",
    "        y_out = y.copy() # So we don’t overwrite y\n",
    "        for i in np.arange(len(spikes)):\n",
    "            if spikes[i] != 0: # If we have an spike in position i\n",
    "                w = np.arange(i-m,i+1+m) # we select 2 m + 1 points around our spike\n",
    "                w2 = w[spikes[w] == 0] # From such interval, we choose the ones which are not spikes\n",
    "                y_out[i] = np.mean(y[w2]) # and we average their values\n",
    "    except:\n",
    "        m = 1\n",
    "        th = 7 # binarization threshold. \n",
    "        spikes = abs(np.array(modified_z_score(np.diff(y)))) > th\n",
    "        y_out = y.copy() # So we don’t overwrite y\n",
    "        for i in np.arange(len(spikes)):\n",
    "            if spikes[i] != 0: # If we have an spike in position i\n",
    "                w = np.arange(i-m,i+1+m) # we select 2 m + 1 points around our spike\n",
    "                w2 = w[spikes[w] == 0] # From such interval, we choose the ones which are not spikes\n",
    "                y_out[i] = np.mean(y[w2]) # and we average their values        \n",
    " \n",
    "    return y_out\n",
    "\n",
    "RGB_SCALE = 255\n",
    "CMYK_SCALE = 100\n",
    "\n",
    "\n",
    "def rgb_to_cmyk(r, g, b):\n",
    "    if (r, g, b) == (0, 0, 0):\n",
    "        # black\n",
    "        return 0, 0, 0, CMYK_SCALE\n",
    "\n",
    "    # rgb [0,255] -> cmy [0,1]\n",
    "    c = 1 - r / RGB_SCALE\n",
    "    m = 1 - g / RGB_SCALE\n",
    "    y = 1 - b / RGB_SCALE\n",
    "\n",
    "    # extract out k [0, 1]\n",
    "    min_cmy = min(c, m, y)\n",
    "    c = (c - min_cmy) / (1 - min_cmy)\n",
    "    m = (m - min_cmy) / (1 - min_cmy)\n",
    "    y = (y - min_cmy) / (1 - min_cmy)\n",
    "    k = min_cmy\n",
    "\n",
    "    # rescale to the range [0,CMYK_SCALE]\n",
    "    return c * CMYK_SCALE, m * CMYK_SCALE, y * CMYK_SCALE, k * CMYK_SCALE\n",
    "# test = df['img'][6][300,:,:,:]/255\n",
    "\n",
    "def rgb_to_cmyk(rgb):\n",
    "\tr, g, b = rgb[...,0], rgb[...,1], rgb[...,2]\n",
    "\tk = 1 - np.max(rgb, axis=-1)\n",
    "\tc = (1-r-k)/(1-k)\n",
    "\tm = (1-g-k)/(1-k)\n",
    "\ty = (1-b-k)/(1-k)\n",
    "\treturn np.dstack([c, m, y, k])\n",
    "\n",
    "def rgb_to_cmyk_2(rgb):\n",
    "\twith np.errstate(invalid='ignore', divide='ignore'):\n",
    "\t\tK = 1 - np.max(test, axis=2)\n",
    "\t\tC = (1-test[...,0] - K)/(1-K)\n",
    "\t\tM = (1-test[...,1] - K)/(1-K)\n",
    "\t\tY = (1-test[...,2] - K)/(1-K)\n",
    "\treturn np.dstack([C, M, Y, K])\n",
    "\n",
    "def sigmoid(x, L ,x0, k, b):\n",
    "    y = L / (1 + np.exp(-k*(x-x0))) + b\n",
    "    return (y)\n",
    "\n",
    "def remove_inf(x, y):\n",
    "    mask = ~np.isinf(x) & ~np.isinf(y)\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "    return x, y\n",
    "\n",
    "def linear(t, b, m):\n",
    "    y = m*t + b\n",
    "    return (y)\n",
    "\n",
    "def avrami(t, k, n):\n",
    "    y = 1 - np.exp(-k*(t)**n)\n",
    "    return (y)\n",
    "\n",
    "def JMAK(t, e, k, n):\n",
    "    R = 8.314 #J/mol/K\n",
    "    T = 273.15+230 #K\n",
    "    t0=0\n",
    "    y = 1 - np.exp(-(k*np.exp(-e/(R*T))*(t-t0))**n)\n",
    "    return (y)\n",
    "\n",
    "def nan_helper(y):\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]\n",
    "\n",
    "\n",
    "# Define the RGB to CMYK conversion function\n",
    "def rgb_to_cmyk(rgb):\n",
    "    r, g, b = rgb[...,0], rgb[...,1], rgb[...,2]\n",
    "    k = 1 - np.max(rgb, axis=-1)\n",
    "    c = (1-r-k)/(1-k)\n",
    "    m = (1-g-k)/(1-k)\n",
    "    y = (1-b-k)/(1-k)\n",
    "    return np.dstack([c, m, y, k])\n",
    "\n",
    "\n",
    "def calculate_K_mean(vm):\n",
    "    K_means = []\n",
    "    for frame in range(vm.shape[0]):\n",
    "        # Convert the frame to CMYK\n",
    "        cmyk_image = rgb_to_cmyk(vm[frame, :, :, :]/255)\n",
    "        \n",
    "        # Extract the K channel\n",
    "        K_channel = cmyk_image[:,:,3]\n",
    "        \n",
    "        # Calculate the 2.5th and 97.5th percentiles (95% CI)\n",
    "        ci_low, ci_high = np.percentile(K_channel, [2.5, 97.5])\n",
    "        \n",
    "        # Mask the values outside the CI\n",
    "        masked_K_channel = np.ma.masked_outside(K_channel, ci_low, ci_high)\n",
    "        \n",
    "        # Calculate the mean of the values within the CI\n",
    "        K_mean = np.ma.mean(masked_K_channel)\n",
    "        \n",
    "        K_means.append(K_mean)\n",
    "        \n",
    "    return K_means\n",
    "\n",
    "\n",
    "def calculate_cv(values):\n",
    "    mean_value = np.nanmean(values)\n",
    "    std_dev = np.nanstd(values)\n",
    "    cv = (std_dev / mean_value) * 100 if mean_value != 0 else 0\n",
    "    return cv\n",
    "\n",
    "\n",
    "\n",
    "def calculate_auc(time_axis, values):\n",
    "    normalized_values = values / np.nanmax(values)\n",
    "    return auc(time_axis, normalized_values)\n",
    "\n",
    "\n",
    "def calculate_k_vm(vm):\n",
    "    return np.array([rgb_to_cmyk(frame) for frame in vm])\n",
    "\n",
    "def calculate_K_delta(values):\n",
    "    return values[0] - values[-1]\n",
    "\n",
    "\n",
    "\n",
    "def process_video(fids, output_path, export_video=True, return_matrix=False, apply_stabilization=True, fps=60, interval=10, crop_x0=500, crop_x1=3850, crop_y0=500, crop_y1=5000):\n",
    "    # Full_frame = slice(crop_x0, crop_x1), slice(crop_y0, crop_y1) #TODO change this w.r.t. your video size, this crops the video, basically crop this to your hot plate or whatever\n",
    "\n",
    "    Full_frame = slice(crop_x0, crop_x1), slice(crop_y0, crop_y1)\n",
    "    \n",
    "    size = (Full_frame[1].stop-Full_frame[1].start, Full_frame[0].stop-Full_frame[0].start)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "    out = None\n",
    "    if export_video:\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, frameSize=size)\n",
    "        if not out.isOpened():\n",
    "            print(\"Error: VideoWriter didn't open\")\n",
    "            return None\n",
    "    \n",
    "    ref_img = cv2.imread(fids[0])\n",
    "    if ref_img is None:\n",
    "        print(\"Error reading reference image\")\n",
    "        return None\n",
    "    \n",
    "    ref_img_cropped = ref_img[Full_frame]\n",
    "    ref_img_cropped_gray = cv2.cvtColor(ref_img_cropped, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask = np.ones_like(ref_img_cropped_gray, dtype=np.uint8)\n",
    "    \n",
    "    num_frames = (len(fids) - 1) // interval\n",
    "    video_matrix = np.zeros((num_frames, size[1], size[0], 3), dtype=np.uint8) if return_matrix else None\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for n in tqdm(range(0, num_frames * interval, interval)):\n",
    "        temp = cv2.imread(fids[n])\n",
    "        if temp is None:\n",
    "            continue\n",
    "        \n",
    "        cropped_temp = temp[Full_frame]\n",
    "        cropped_temp_gray = cv2.cvtColor(cropped_temp, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if apply_stabilization:\n",
    "            warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "            criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 5000, 1e-6)\n",
    "            _, warp_matrix = cv2.findTransformECC(ref_img_cropped_gray, cropped_temp_gray, warp_matrix, cv2.MOTION_EUCLIDEAN, criteria, inputMask=mask, gaussFiltSize=5)\n",
    "            aligned_temp = cv2.warpAffine(cropped_temp, warp_matrix, (size[0], size[1]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "        else:\n",
    "            aligned_temp = cropped_temp\n",
    "        \n",
    "        if export_video:\n",
    "            out.write(aligned_temp)\n",
    "        \n",
    "        if return_matrix:\n",
    "            video_matrix[counter] = aligned_temp\n",
    "            counter += 1\n",
    "    \n",
    "    if export_video:\n",
    "        out.release()\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    if return_matrix:\n",
    "        return video_matrix\n",
    "    \n",
    "\n",
    "\n",
    "def apply_perspective_transform(frame, M, cols, rows):\n",
    "    return cv2.warpPerspective(frame, M, (cols, rows))\n",
    "\n",
    "\n",
    "def fit_data_and_find_x_intercept(K_mean, frame_axis, start=2000, stop=3000, sigma=15):\n",
    "    if K_mean is None or np.isnan(K_mean).all():\n",
    "        return None\n",
    "\n",
    "    K_mean_array = np.array(K_mean)\n",
    "    K_mean_array = K_mean_array[~np.isnan(K_mean_array)]\n",
    "    # sigma = 15\n",
    "\n",
    "    smoothed_norm_k_mean_values = gaussian_filter(K_mean_array, sigma) / np.nanmax(K_mean_array)\n",
    "    \n",
    "    frame_axis_array = np.array(frame_axis)[:len(K_mean_array)]\n",
    "    mask = (frame_axis_array >= start) & (frame_axis_array <= stop)\n",
    "    fit_x = frame_axis_array[mask]\n",
    "    fit_y = 1 - smoothed_norm_k_mean_values[mask]\n",
    "\n",
    "    coefficients = np.polyfit(fit_x, fit_y, 1)\n",
    "    slope, intercept = coefficients\n",
    "\n",
    "    x_intercept = -intercept / slope if slope != 0 else None\n",
    "\n",
    "    return x_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_creation_date(image_path):\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            exif_data = img._getexif()\n",
    "            if exif_data is not None:\n",
    "                for tag, value in exif_data.items():\n",
    "                    tag_name = TAGS.get(tag, tag)\n",
    "                    if tag_name == 'DateTimeOriginal':\n",
    "                        return value\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading EXIF data for {image_path}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creation_time = []\n",
    "image_folder_0 = 'gopro_images/'\n",
    "go_pro_folders = os.listdir(image_folder_0)\n",
    "fids_0 = {}\n",
    "for folder in go_pro_folders:\n",
    "    if folder not in fids_0:\n",
    "        fids_0[folder] = []\n",
    "    folder_path = os.path.join(image_folder_0, folder)\n",
    "    images = os.listdir(folder_path)\n",
    "    for image in images:\n",
    "        if 'control' not in image or '_rgb' in image:\n",
    "            image_path = os.path.join(folder_path, image)\n",
    "            creation_time = get_image_creation_date(image_path)\n",
    "            fids_0[folder].append((image_path, creation_time))\n",
    "# Filter the files based on your conditions\n",
    "# fids_0 = []\n",
    "# creation_time = []\n",
    "# for f in all_files:\n",
    "#     if 'control' not in f or '_rgb' in f:\n",
    "#         file_path = os.path.join(image_folder_0, f)\n",
    "#         creation_time.append(get_image_creation_date(file_path))\n",
    "#         fids_0.append(image_folder_0 + f)\n",
    "# fids_0 = natsorted(fids_0)\n",
    "# fids_0\n",
    "fids_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"test_video/\"\n",
    "\n",
    "slice_dict = {}\n",
    "# Folder_name : ((x0,x1),(y0,y1))\n",
    "# try to get sizes to 175 x 620 pixels\n",
    "slice_dict['100GOPRO'] = ((1080,1255),(1390,2010))\n",
    "slice_dict['101GOPRO'] = ((1095,1280),(1365,1985))\n",
    "slice_dict['102GOPRO'] = ((980,1165),(1300,1920))\n",
    "slice_dict['103GOPRO'] = ((980,1165),(1300,1920))\n",
    "slice_dict['104GOPRO'] = ((980,1165),(1300,1920))\n",
    "slice_dict['105GOPRO'] = ((995,1140),(1280,1900))\n",
    "slice_dict['106GOPRO'] = ((995,1140),(1280,1900))\n",
    "slice_dict['107GOPRO'] = ((995,1140),(1280,1900))\n",
    "slice_dict['108GOPRO'] = ((995,1140),(1280,1900))\n",
    "slice_dict['109GOPRO'] = ((995,1140),(1280,1900))\n",
    "slice_dict['110GOPRO'] = ((995,1140),(1280,1900))\n",
    "slice_dict['111GOPRO'] = ((995,1140),(1280,1900))\n",
    "slice_dict['112GOPRO'] = ((995,1140),(1280,1900))\n",
    "slice_dict['113GOPRO'] = ((995,1140),(1280,1900))\n",
    "# d\n",
    "# change interval here according to the # of images in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(img, crop_params):\n",
    "    x0, x1 = crop_params[0]\n",
    "    y0, y1 = crop_params[1]\n",
    "    return img[x0:x1, y0:y1]\n",
    "\n",
    "def create_video_matrix(folder_name, slice_dict):\n",
    "    \n",
    "    # first_image = cv2.imread(fids_0[folder_name][0][0])\n",
    "    # height, width, channels = first_image.shape\n",
    "\n",
    "    # # Initialize the video matrix\n",
    "    num_frames = len(fids_0[folder_name])\n",
    "    video_matrix = None\n",
    "\n",
    "    # Read each image, crop it, and populate the video matrix\n",
    "    for i, info in enumerate(fids_0[folder_name]):\n",
    "\n",
    "        image_path = info[0]\n",
    "        frame = cv2.imread(image_path)\n",
    "        \n",
    "\n",
    "        crop_params = slice_dict[folder_name]\n",
    "        frame = crop_image(frame, crop_params)\n",
    "        height, width, channels = frame.shape\n",
    "        if video_matrix is None:\n",
    "            video_matrix = np.zeros((num_frames, height, width, channels), dtype=np.uint8)\n",
    "\n",
    "        video_matrix[i] = frame\n",
    "\n",
    "    return video_matrix\n",
    "video_matrix = create_video_matrix('107GOPRO', slice_dict = slice_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_matrix.size*video_matrix.itemsize/1e9 # GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the points in the original image (corners of the original image)\n",
    "rows, cols = video_matrix.shape[1:3]\n",
    "pts1 = np.float32([[20, 15], [cols-30, 5], [0, rows], [cols + 20, rows]])  # top left, top right, bottom left, bottom right\n",
    "print(rows, cols)\n",
    "# Define the magnitude of the transformation (e.g., 0.05 for a 5% stretch at the top)\n",
    "magnitude = 0.02\n",
    "\n",
    "# Define where those points will be in the transformed image (stretching the top)\n",
    "pts2 = np.float32([[0, -rows * magnitude], [cols - 1, -rows * magnitude], [0, rows - 1], [cols - 1, rows - 1]])\n",
    "\n",
    "# Compute the perspective transformation matrix\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "# Get the first original image from video_matrix\n",
    "original_image = video_matrix[0, :, :, 1]\n",
    "\n",
    "# Apply the transformation to the first frame to see what it looks like\n",
    "transformed_image = apply_perspective_transform(original_image, M, cols, rows)\n",
    "\n",
    "# Display the original image using Plotly Express\n",
    "fig_original = px.imshow(original_image)\n",
    "fig_original.show()\n",
    "\n",
    "# Display the transformed image using Plotly Express\n",
    "fig_transformed = px.imshow(transformed_image)\n",
    "fig_transformed.show()\n",
    "\n",
    "# # If the transformed image looks good, uncomment the following lines to apply the transformation to the whole video_matrix\n",
    "# for i in tqdm(range(video_matrix.shape[0])):\n",
    "#     video_matrix[i, :, :, :] = apply_perspective_transform(video_matrix[i, :, :, :], M, cols, rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a blank matrix with placeholders for 64 samples in a format similar to center_points_0\n",
    "# Create an 8x8 blank matrix with placeholders (None) for each sample\n",
    "center_points_0 = np.full((4, 10), None, dtype=object)\n",
    "for i, x in enumerate(np.linspace(0+15,rows-15,4)):\n",
    "    for j, y in enumerate(np.linspace(0 + 30, cols-30, 10)):\n",
    "        center_points_0[i,j] = (int(x),int(y))\n",
    "\n",
    "# Lookup table\n",
    "sample_names_0 = np.arange(0,40).reshape(4,10)\n",
    "sample_names_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the original or transformed image\n",
    "plt.imshow(transformed_image, cmap='gray')\n",
    "\n",
    "# Loop through sample_names_0 and center_points_0 to annotate the image\n",
    "for i in range(center_points_0.shape[0]):\n",
    "    for j in range(center_points_0.shape[1]):\n",
    "        x, y = center_points_0[i, j]\n",
    "        sample_name = sample_names_0[i, j]\n",
    "        \n",
    "        # Annotate the image\n",
    "        plt.text(y, x, str(sample_name), color='white', fontsize=10, ha='center', va='center')\n",
    "\n",
    "# # Show the image with annotations\n",
    "# plt.axis('off')\n",
    "# # make it tight\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size (70 pixels in x and y)\n",
    "window_size = 13 # idk why\n",
    "num_frames = video_matrix.shape[0]\n",
    "\n",
    "# Create a slice matrix to hold the slices\n",
    "slice_shape = (2 * window_size, 2 * window_size, video_matrix.shape[3])\n",
    "slice_matrix = np.empty((*sample_names_0.shape, *slice_shape))\n",
    "\n",
    "# Extract the slices from the video_matrix using the center points\n",
    "for i in range(sample_names_0.shape[0]):\n",
    "    for j in range(sample_names_0.shape[1]):\n",
    "        x, y = center_points_0[i, j]\n",
    "\n",
    "        # Boundary checks\n",
    "        x_min = max(0, x - window_size)\n",
    "        x_max = min(video_matrix.shape[2], x + window_size)\n",
    "        y_min = max(0, y - window_size)\n",
    "        y_max = min(video_matrix.shape[1], y + window_size)\n",
    "\n",
    "        temp_slice = video_matrix[0, y_min:y_max, x_min:x_max, :]\n",
    "\n",
    "        # Padding in case the slice is smaller than the window\n",
    "        pad_x_min = window_size - (x - x_min)\n",
    "        pad_x_max = window_size + (x_max - x)\n",
    "        pad_y_min = window_size - (y - y_min)\n",
    "        pad_y_max = window_size + (y_max - y)\n",
    "\n",
    "        slice_matrix[i, j, pad_y_min:pad_y_max, pad_x_min:pad_x_max, :] = temp_slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to hold the data for each sample\n",
    "samples_data = []\n",
    "\n",
    "# Iterate through the samples in the slice_matrix\n",
    "for i in tqdm(range(slice_matrix.shape[0])):\n",
    "    for j in range(slice_matrix.shape[1]):\n",
    "        # Extract the sample name\n",
    "        sample_name = sample_names_0[i, j]\n",
    "\n",
    "        # Create a new video matrix for the current sample\n",
    "        sample_video_matrix = np.empty((num_frames, *slice_shape))\n",
    "\n",
    "        # Extract the slices for the current sample from the video_matrix\n",
    "        for frame in range(num_frames):\n",
    "            x, y = center_points_0[i, j]\n",
    "            if np.isnan(x) or np.isnan(y):\n",
    "                continue # Skip if x or y is NaN\n",
    "            x, y = int(x), int(y)\n",
    "\n",
    "            # Check that the coordinates are within valid bounds\n",
    "            if x - window_size < 0 or x + window_size >= video_matrix.shape[2] or y - window_size < 0 or y + window_size >= video_matrix.shape[1]:\n",
    "                continue # Skip if coordinates are too close to the edges\n",
    "\n",
    "            sample_video_matrix[frame] = video_matrix[frame, y-window_size:y+window_size, x-window_size:x+window_size, :]\n",
    "\n",
    "        # Append the current sample's data to the list\n",
    "        samples_data.append((sample_name, sample_video_matrix))\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame from the list of samples data\n",
    "all_samples_df = pd.DataFrame(samples_data, columns=['sample', 'VM'])\n",
    "\n",
    "# You now have a DataFrame (all_samples_df) that contains the sample names and video matrices for all samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_df['K_VM'] = all_samples_df['VM'].apply(calculate_k_vm)\n",
    "\n",
    "all_samples_df['RGB_mean'] = all_samples_df['VM'].apply(\n",
    "    lambda vm: [np.mean(vm[frame, :, :, :], axis=(0, 1)) for frame in range(vm.shape[0])]\n",
    ")\n",
    "time_axis = [frame * 5*100 / 60**2 for frame in range(len(all_samples_df.loc[0, 'RGB_mean']))] # in hours: 120 is the camera picture interval in seconds * 10 for the interval of 10\n",
    "frame_axis = [frame for frame in range(len(all_samples_df.loc[0, 'RGB_mean']))]\n",
    "\n",
    "# Apply the function to the 'VM' column of the DataFrame\n",
    "all_samples_df['K_mean'] = all_samples_df['VM'].apply(calculate_K_mean)\n",
    "# all_samples_df['cv'] = all_samples_df['RGB_mean'].apply(calculate_cv)\n",
    "# all_samples_df['auc'] = all_samples_df['K_mean'].apply(lambda x: calculate_auc(time_axis,x))\n",
    "\n",
    "all_samples_df['K_delta'] = all_samples_df['K_mean'].apply(calculate_K_delta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_samples_df['x_intercept'] = all_samples_df['K_mean'].apply(\n",
    "#     fit_data_and_find_x_intercept, \n",
    "#     args=(frame_axis, 5, 18, 2)\n",
    "# )\n",
    "# # fitting needs work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the sample values you're interested in\n",
    "# samples_to_nan = [47, 46, 45, 36, 17]\n",
    "\n",
    "# # Set all other column values to NaN for these samples\n",
    "# all_samples_df.loc[all_samples_df['sample'].isin(samples_to_nan), 'VM':'K_delta'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "filtered_df = all_samples_df.dropna(subset=['K_mean'])\n",
    "\n",
    "sigma = 1\n",
    "\n",
    "color_data = []\n",
    "\n",
    "# Your existing code for plotting\n",
    "for index, row in filtered_df.iterrows():\n",
    "    k_mean_values = row['K_mean']\n",
    "    smoothed_norm_k_mean_values = gaussian_filter(k_mean_values, sigma) / np.nanmax(gaussian_filter(k_mean_values, sigma)) - (np.nanmin(gaussian_filter(k_mean_values, sigma)) / np.nanmax(gaussian_filter(k_mean_values, sigma)))\n",
    "    smoothed_norm_k_mean_values = smoothed_norm_k_mean_values/np.nanmax(smoothed_norm_k_mean_values)\n",
    "\n",
    "    color_data.append(smoothed_norm_k_mean_values)\n",
    "    # smoothed_norm_k_mean_values = gaussian_filter(k_mean_values, sigma) / np.nanmax(k_mean_values)\n",
    "    plt.plot(frame_axis, 1-smoothed_norm_k_mean_values, alpha=1)\n",
    "\n",
    "\n",
    "# add a vertical line\n",
    "# plt.axvline(x=2700, color='k', linestyle='--', linewidth=1)\n",
    "# plt.axvline(x=2900, color='k', linestyle='--', linewidth=1)\n",
    "# Set major ticks at intervals of 24\n",
    "ax = plt.gca()\n",
    "# ax.xaxis.set_major_locator(MultipleLocator(24))\n",
    "\n",
    "# Set minor ticks at intervals of 6\n",
    "# ax.xaxis.set_minor_locator(MultipleLocator(6))\n",
    "\n",
    "plt.xlim(0, 20)\n",
    "# plt.ylim(0, .6)\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('1-cmyk_AverageK_95ci')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#the next resonable step would be to fit the linear portion of these 'S' shape curves to get an onset value to further dimensionality reduce.\n",
    "## Note samples that did not degrade by end of test look odd, e.g. max value will not be at end of measurement, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_data\n",
    "# observation: each array corresponds to a single sample as its hard coded in the lookup table. 8 frames long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Scratch work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra: To make a color bar out of images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c86dfbc17468201bf110f641e56a1df81e3c9871b3a7a52a78db9d9bb9a33d6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
